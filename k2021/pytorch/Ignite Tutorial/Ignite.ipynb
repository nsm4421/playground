{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ignite.engine import Engine\n",
    "from ignite.engine import Events\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import MyDataset\n",
    "from model import MyModel\n",
    "from engine import MyEngine\n",
    "from trainer import MyTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'MNIST_SAVE_PATH' : os.path.join(os.getcwd(), './data'), \n",
    "    'MODEL_FN' : './model.pt',\n",
    "    'N_EPOCH' : 10,\n",
    "    'BATCH_SIZE' : 64, \n",
    "    'lr' : 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def get_train_dataset(self):\n",
    "        return datasets.MNIST(root='./data',\n",
    "                download=True,\n",
    "                train=True,\n",
    "                transform=transforms.Compose([\n",
    "                transforms.Resize(28),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((.5), (.5))])) \n",
    "\n",
    "    def get_test_dataset(self):\n",
    "        return datasets.MNIST(root='./data', \n",
    "                download=True,\n",
    "                train=False,\n",
    "                transform= transforms.Compose([\n",
    "                transforms.Resize(28),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((.5),(.5))]))\n",
    "                \n",
    "    def get_train_loader(self):\n",
    "        return DataLoader(self.get_train_dataset(),\n",
    "                        batch_size=self.config['BATCH_SIZE'],\n",
    "                        shuffle=True)\n",
    "\n",
    "    def get_test_loader(self):\n",
    "        return DataLoader(self.get_test_dataset(),\n",
    "                        batch_size=self.config['BATCH_SIZE'],\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\N\\Desktop\\N\\프로그래밍\\NLP\\.venv\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(config)\n",
    "train_loader = dataset.get_train_loader()\n",
    "test_loader = dataset.get_test_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2) \n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.dense = nn.Linear(in_features = 256, out_features=120)\n",
    "        self.dense2 = nn.Linear(in_features = 120, out_features=84)\n",
    "        self.dense3 = nn.Linear(in_features = 84, out_features=10)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.flat(x)\n",
    "\n",
    "        x = self.dense(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dense2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dense3(x)\n",
    "        return F.softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (conv): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dense): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (dense2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (dense3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "            lr = config['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyEngine(Engine):\n",
    "    def __init__(self, func, model, criterion, optimizer, config):\n",
    "        \"\"\"\n",
    "        func : torch ignite를 돌리는 함수\n",
    "        - 아래에서 구현한 static method를 인수로 넣어주면 됨 (train, test, attach...)\n",
    "        - 그 외에 부분 (model, criterion, optimizer, config)은 직접 지정\n",
    "        \"\"\"        \n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        if 'MODEL_FN' not in config.keys():config['MODEL_FN'] = './model.pt'\n",
    "        self.config = config\n",
    "        super().__init__(func)\n",
    "\n",
    "        self.best_loss = np.inf\n",
    "        self.best_model = None\n",
    "        \n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "    @staticmethod\n",
    "    def train(engine, batch):\n",
    "        def acc(prediction, label):                     # 정확도\n",
    "            assert prediction.size(0) == label.size(0)\n",
    "            batch_size = prediction.size(0)\n",
    "            _, prediction = torch.max(prediction.data, 1)\n",
    "            return float((prediction == label).sum().item()/batch_size)\n",
    "\n",
    "        engine.model.train()                            # test 모드\n",
    "        engine.optimizer.zero_grad()                    # optimizer 초기화\n",
    "\n",
    "        device = engine.device\n",
    "        image, label = batch\n",
    "        batch_size = image.size(0)\n",
    "        if image.shape != [batch_size, 1, 28, 28]:      # 채널길이\n",
    "            image=image.reshape(batch_size, 1, 28, 28)\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)  \n",
    "\n",
    "        prediction = engine.model(image)                 # 예측\n",
    "        loss = engine.criterion(prediction, label)\n",
    "        loss.backward()                                 # gradient계산\n",
    "        engine.optimizer.step()                         # 업데이트\n",
    "      \n",
    "        return {'loss' : float(loss), 'accuracy' : acc(prediction, label)}      # metric 반환\n",
    "\n",
    "    @staticmethod\n",
    "    def test(engine, batch):\n",
    "        \n",
    "        def acc(prediction, label):                     # 정확도\n",
    "            assert prediction.size(0) == label.size(0)\n",
    "            batch_size = prediction.size(0)\n",
    "            _, prediction = torch.max(prediction.data, 1)\n",
    "            return float((prediction == label).sum().item()/batch_size)\n",
    "\n",
    "        engine.model.eval()                             # 평가 모드\n",
    "        with torch.no_grad():                           # gradient 계산 x (이래야 더 빠름)\n",
    "            device = engine.device\n",
    "            image, label = batch\n",
    "            batch_size = image.size(0)          \n",
    "            if image.shape != [batch_size, 1, 28, 28]:  # 채널길이\n",
    "                image=image.reshape(batch_size, 1, 28, 28)\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            prediction = engine.model(image)\n",
    "            loss = engine.criterion(prediction, label)        \n",
    "\n",
    "            return {'loss' : float(loss), 'accuracy' : acc(prediction, label)}   # metric 반환\n",
    "\n",
    "    @staticmethod\n",
    "    def attach(train_engine, test_engine):\n",
    "        \"\"\"\n",
    "        engine에 status bar와 progress bar를 붙여주는 부분\n",
    "        \"\"\"\n",
    "        \n",
    "        metrics = ['loss', 'accuracy']\n",
    "\n",
    "        def attach_running_average(engine, metric):\n",
    "            RunningAverage(output_transform=lambda x:x[metric]).attach(engine, metric,)\n",
    "        for metric in metrics:\n",
    "            attach_running_average(train_engine, metric)\n",
    "            attach_running_average(test_engine, metric)\n",
    "\n",
    "        # train\n",
    "        ProgressBar(bar_format=None, ncols=100).attach(train_engine, metrics)\n",
    "        @train_engine.on(Events.EPOCH_COMPLETED)\n",
    "        def print_train_status(engine):\n",
    "            print(f\"Train | epoch {engine.state.epoch} - \\\n",
    "                loss : {round(float(engine.state.metrics['loss']), 2)} - \\\n",
    "                    accuracy : {round(float(engine.state.metrics['accuracy']*100), 2)} %\")\n",
    "\n",
    "        # test\n",
    "        ProgressBar(bar_format=None, ncols=100).attach(test_engine, metrics)\n",
    "        @test_engine.on(Events.EPOCH_COMPLETED)\n",
    "        def print_test_status(engine):\n",
    "            print(f\"Test | - loss : {round(float(engine.state.metrics['loss']), 2)} - \\\n",
    "                    accuracy : {round(float(engine.state.metrics['accuracy']*100), 2)} %\")\n",
    "\n",
    "    @staticmethod\n",
    "    def check_best(engine):\n",
    "        \"\"\"\n",
    "        가장 loss값이 작은 경우 copy해서 engine.best_model에 저장\n",
    "        \"\"\"\n",
    "        current_loss = float(engine.state.metrics['loss'])\n",
    "        if current_loss < engine.best_loss:\n",
    "            engine.best_loss = current_loss    \n",
    "            engine.best_model = deepcopy(engine.model.state_dict())\n",
    "        print(f\"\\n model updated  - loss : {round(engine.best_loss, 4)} \")\n",
    "        \n",
    "    @staticmethod\n",
    "    def save_model(engine, train_engine, config, **kwargs):\n",
    "        torch.save({'model' : engine.best_model, 'config' : config, **kwargs},\n",
    "            config.MODEL_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer:\n",
    "    def __init__(self, config):\n",
    "        if 'N_EPOCH' not in config.keys():\n",
    "            self.config['N_EPOCH'] = 20\n",
    "        self.config = config\n",
    "    \n",
    "    def train(self, model, criterion, optimizer, train_loader, valid_loader):\n",
    "        \n",
    "        # engine\n",
    "        train_engine = MyEngine(func=MyEngine.train, model=model, criterion=criterion,\\\n",
    "            optimizer=optimizer, config=self.config)\n",
    "        valid_engine = MyEngine(func=MyEngine.test, model=model, criterion=criterion,\\\n",
    "            optimizer=optimizer, config=self.config)\n",
    "        \n",
    "        # attach\n",
    "        MyEngine.attach(train_engine=train_engine, test_engine=valid_engine)\n",
    "        \n",
    "        # add event handler\n",
    "        \"\"\"\n",
    "            매 epoch마다 validation을 하고, 성능이 제일 좋은 (loss가 작은) 모델을 best_model로 deep copy\n",
    "        \"\"\"\n",
    "        def run_validation(engine, valid_engine, valid_loader):\n",
    "            valid_engine.run(valid_loader, max_epochs=1)\n",
    "        train_engine.add_event_handler(Events.EPOCH_COMPLETED, run_validation, valid_engine, valid_loader)\n",
    "        valid_engine.add_event_handler(Events.EPOCH_COMPLETED, MyEngine.check_best)     \n",
    "        \n",
    "        # train\n",
    "        train_engine.run(train_loader, max_epochs=self.config['N_EPOCH'])\n",
    "    \n",
    "        model.load_state_dict(valid_engine.best_model)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MyTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | epoch 1 -                 loss : 1.49 -                     accuracy : 97.38 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | - loss : 1.48 -                     accuracy : 98.31 %\n",
      "\n",
      " model updated  - loss : 1.4791 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | epoch 2 -                 loss : 1.49 -                     accuracy : 97.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | - loss : 1.48 -                     accuracy : 98.35 %\n",
      "\n",
      " model updated  - loss : 1.4784 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | epoch 3 -                 loss : 1.49 -                     accuracy : 97.52 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | - loss : 1.48 -                     accuracy : 98.64 %\n",
      "\n",
      " model updated  - loss : 1.4769 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | epoch 4 -                 loss : 1.48 -                     accuracy : 97.96 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | - loss : 1.48 -                     accuracy : 98.58 %\n",
      "\n",
      " model updated  - loss : 1.4769 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | epoch 5 -                 loss : 1.48 -                     accuracy : 98.2 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | - loss : 1.48 -                     accuracy : 98.53 %\n",
      "\n",
      " model updated  - loss : 1.4768 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | epoch 6 -                 loss : 1.48 -                     accuracy : 98.2 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | - loss : 1.48 -                     accuracy : 98.64 %\n",
      "\n",
      " model updated  - loss : 1.4762 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | epoch 7 -                 loss : 1.48 -                     accuracy : 98.62 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | - loss : 1.48 -                     accuracy : 98.71 %\n",
      "\n",
      " model updated  - loss : 1.4753 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | epoch 8 -                 loss : 1.48 -                     accuracy : 98.55 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | - loss : 1.47 -                     accuracy : 98.74 %\n",
      "\n",
      " model updated  - loss : 1.4745 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | epoch 9 -                 loss : 1.48 -                     accuracy : 98.22 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | - loss : 1.48 -                     accuracy : 98.7 %\n",
      "\n",
      " model updated  - loss : 1.4745 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | epoch 10 -                 loss : 1.48 -                     accuracy : 98.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | - loss : 1.47 -                     accuracy : 98.7 %\n",
      "\n",
      " model updated  - loss : 1.4745 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "best_model = trainer.train(model=model, criterion=criterion, optimizer=optimizer, \\\n",
    "    train_loader=train_loader, valid_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b59b2cefb315bcb172c13f59a4a58544a4a8d35c888b13beebd5360c7ab03cf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
